# ğŸ¥ MediTranslate â€” Healthcare Doctor-Patient Translation App

> Real-time AI-powered translation bridge between doctors and patients, featuring voice input/output, medical-context-aware translation, and intelligent clinical summarization.

**ğŸ”— Live Demo:** https://health-care-assistant-system.vercel.app  
**ğŸ“‚ Repository:** https://github.com/Sajjad01-chaus/HealthCare_Assistant_System/

---

## ğŸ“Œ Project Overview

MediTranslate is a full-stack web application that enables real-time communication between doctors and patients who speak different languages. It features a complete **multimodal voice pipeline** â€” doctors and patients can speak in their language and the other person **hears** the translation spoken aloud. The app also supports text chat, conversation persistence, keyword search, and intelligent medical summarization.

Built for the Pre-Interview Take-Home Assignment â€” designed and developed within a **12-hour** time constraint.

---

## âœ… Features Attempted & Completed

| # | Feature | Status | Details |
|---|---------|--------|---------|
| 1 | **Real-Time Translation** | âœ… Complete | WebSocket-based instant translation between Doctor â†” Patient |
| 2 | **Text Chat Interface** | âœ… Complete | WhatsApp-style UI with role-based message bubbles |
| 3 | **Voice Input + Audio Output** | âœ… Complete | Record â†’ Transcribe â†’ Translate â†’ **Speak translated audio to listener** |
| 4 | **Conversation Logging** | âœ… Complete | All messages persisted in PostgreSQL with timestamps |
| 5 | **Conversation Search** | âœ… Complete | Keyword search across messages with highlighted context |
| 6 | **AI Medical Summary** | âœ… Complete | Structured extraction of symptoms, diagnoses, medications, follow-ups |

### Bonus Features
- ğŸ”Š **Text-to-Speech Output** â€” Translations are spoken aloud via Edge-TTS / gTTS neural voices
- ğŸ”Š **Auto-Speak Toggle** â€” Incoming translations auto-play as audio for hands-free operation
- ğŸ”— **Shareable Room Links** â€” Doctor shares a URL for the patient to join the same room
- ğŸŒ **20 Languages Supported** â€” English, Hindi, Bengali, Tamil, Telugu, Urdu, Chinese, Korean, Japanese, Arabic, Spanish, French, German, Portuguese, Russian, Italian, Dutch, Thai, Vietnamese, Turkish
- ğŸ¯ **Role Toggle** â€” Switch between Doctor/Patient view on the same device
- ğŸ“± **Mobile-Responsive UI** â€” Works on phones and tablets
- ğŸ—£ï¸ **Auto Language Detection** â€” Whisper auto-detects the spoken language
- ğŸ©º **Role-Aware Translation** â€” Doctor messages preserve medical terminology; Patient messages use simple language

---

## ğŸ”Š Voice Pipeline â€” The Key Differentiator

MediTranslate lets participants **hear** the translation â€” critical in a clinical setting where a patient may not be able to read a screen.

```
Doctor speaks Korean ğŸ¤
    â”‚
    â–¼
Browser records audio (WebM)
    â”‚
    â–¼
Groq Whisper large-v3 â†’ Transcribes: "í™˜ìê°€ ë‘í†µì´ ìˆìŠµë‹ˆë‹¤"
    â”‚
    â–¼
Groq Llama 3.3 70B â†’ Translates to Chinese: "æ‚£è€…å¤´ç—›"
    â”‚                   (medical-context-aware, role-adapted)
    â–¼
Edge-TTS / gTTS â†’ Generates Chinese audio
    â”‚
    â–¼
WebSocket broadcasts to room:
    â†’ Patient SEES: Korean original + Chinese translation
    â†’ Patient HEARS: Chinese audio auto-plays ğŸ”Š
```

### Three-Layer Audio Fallback
1. **Primary:** Server-side Edge-TTS (high-quality Microsoft neural voices)
2. **Fallback:** Google TTS (gTTS) if Edge-TTS fails
3. **Manual:** Click ğŸ”Š button on any message to hear it

### Doctor vs Patient Voices
Each language has distinct voices so participants can distinguish who is speaking:

| Language | Patient Voice | Doctor Voice |
|----------|--------------|--------------|
| English | Jenny (female) | Guy (male) |
| Hindi | Swara (female) | Madhur (male) |
| Chinese | Xiaoxiao (female) | Yunxi (male) |
| Korean | SunHi (female) | InJoon (male) |
| *...and 16 more* | | |

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Why This Choice |
|-------|-----------|-----------------|
| **Frontend** | React 18 (Vite) + Tailwind CSS | Fast build times, utility-first CSS for rapid UI development |
| **Backend** | FastAPI (Python) | Async-native, WebSocket support, fast development |
| **Database** | SQLite (dev) â†’ PostgreSQL (prod) | Zero-config locally, production-ready on Render |
| **Real-Time** | WebSockets (native FastAPI) | True bidirectional communication, no polling overhead |
| **Translation** | Groq API â€” Llama 3.3 70B | Blazing fast inference (276 tok/s), reliable free tier, strong multilingual |
| **Speech-to-Text** | Groq API â€” Whisper large-v3 | Fastest Whisper endpoint available, multilingual, same API key |
| **Text-to-Speech** | Edge-TTS + gTTS fallback | Free neural voices, 20+ languages, distinct doctor/patient voices |
| **Medical Summary** | Groq API â€” Llama 3.3 70B | Strong reasoning for structured medical extraction |
| **Deployment** | Render (backend) + Vercel (frontend) | Free tier, easy CI/CD, WebSocket support |

### Why Groq + Llama 3.3 for Translation?

After researching current LLM translation benchmarks (Feb 2026):
- **Qwen-MT (Turbo)** â€” best-in-class translation model (92 languages) but requires Alibaba Cloud setup, too much overhead for a 12-hour sprint
- **Gemini 2.5 Flash** â€” excels at Indian languages but free tier was slashed in Dec 2025 (10 RPM, 250 RPD), risky for demo evaluation
- **Llama 3.3 70B on Groq** â€” strong multilingual capabilities, 276 tokens/second inference, reliable free tier. Optimal for demo stability + speed

The key differentiator is **medical-context-aware prompts** â€” the system uses role-aware translation that preserves medical terminology accuracy while adapting complexity for patient vs. doctor communication.

---

## ğŸ¤– AI Tools & Resources Leveraged

| Tool | How I Used It |
|------|---------------|
| **Claude (Anthropic)** | Architecture planning, code generation assistance, research on translation LLMs |
| **Groq API** | Core AI provider for translation (Llama 3.3), transcription (Whisper), and summarization |
| **Edge-TTS + gTTS** | Neural text-to-speech for translated audio output |
| **GitHub Copilot** | Code autocompletion during development |
| **Tailwind CSS docs** | UI styling reference |
| **FastAPI docs** | WebSocket implementation reference |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FRONTEND (React + Vite + Tailwind)         â”‚
â”‚  Role Toggle Â· Chat UI Â· Audio Recorder            â”‚
â”‚  Auto-Speak Toggle Â· TTS Playback                  â”‚
â”‚  Search Modal Â· Summary Panel Â· Share Link         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ WebSocket â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND (FastAPI)                     â”‚
â”‚  /ws/{id}            Real-time messaging + TTS     â”‚
â”‚  /api/conversations   CRUD operations              â”‚
â”‚  /api/audio           Voice pipeline:              â”‚
â”‚                       Record â†’ Whisper â†’ Translate â”‚
â”‚                       â†’ TTS â†’ Broadcast            â”‚
â”‚  /api/tts             Standalone TTS endpoint      â”‚
â”‚  /api/search          Keyword search               â”‚
â”‚  /api/summary         Medical AI summary           â”‚
â”‚  /api/health          Service health check         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚ â”‚ Groq API  â”‚ â”‚ Edge-TTS/gTTS â”‚
â”‚ (Messages,  â”‚ â”‚ Llama 3.3 â”‚ â”‚ (Neural       â”‚
â”‚  Summaries, â”‚ â”‚ Whisper   â”‚ â”‚  Voices)      â”‚
â”‚  History)   â”‚ â”‚ large-v3  â”‚ â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow: Text Message
```
User types message â†’ WebSocket â†’ Llama 3.3 translates
  â†’ Edge-TTS generates audio â†’ Store in DB â†’ Broadcast to room
```

### Data Flow: Voice Message
```
User records audio â†’ Upload â†’ Whisper transcribes â†’ Llama 3.3 translates
  â†’ Edge-TTS generates speech in target language â†’ Store in DB
  â†’ Broadcast original audio + transcription + translation + TTS audio
```

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.10+
- Node.js 18+
- Groq API key (free at [console.groq.com](https://console.groq.com))

### Backend Setup
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Create .env file
cp .env.example .env
# Add your GROQ_API_KEY to .env

# Run the server
uvicorn main:app --reload --port 8000
```

### Frontend Setup
```bash
cd frontend
npm install
npm run dev
```

Open `http://localhost:5173` â€” you're ready to go!

---

## âš ï¸ Known Limitations & Trade-offs

| Limitation | Reason | Potential Fix |
|-----------|--------|---------------|
| Audio files stored locally | No cloud storage (S3) in 12hr sprint | Integrate S3 or Cloudinary |
| No user authentication | Focused on core features within time limit | Add JWT auth with role-based access |
| Translation accuracy varies | Llama 3.3 strongest in top-20 languages | Add specialized models as fallback |
| Browser may block autoplay | Browser security policy | Click any ğŸ”Š button once to enable |
| Render free tier cold starts | First request after 15min idle takes ~50s | Use UptimeRobot to keep warm |

---

## ğŸ“ Project Structure

```
healthcare-translator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI app entry point
â”‚   â”œâ”€â”€ database.py              # SQLAlchemy connection
â”‚   â”œâ”€â”€ models.py                # Database models
â”‚   â”œâ”€â”€ schemas.py               # Pydantic schemas + 20 languages
â”‚   â”œâ”€â”€ ws_manager.py            # WebSocket room-based connection manager
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ conversations.py     # Conversation CRUD
â”‚   â”‚   â”œâ”€â”€ messages.py          # Message send/receive with translation
â”‚   â”‚   â”œâ”€â”€ audio.py             # Voice pipeline: Record â†’ STT â†’ Translate â†’ TTS
â”‚   â”‚   â”œâ”€â”€ summary.py           # AI medical summary
â”‚   â”‚   â”œâ”€â”€ search.py            # Keyword search
â”‚   â”‚   â””â”€â”€ websocket.py         # Real-time WebSocket handler with TTS
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ groq_service.py      # Groq: Llama translation + Whisper STT + Summaries
â”‚   â”‚   â””â”€â”€ tts_service.py       # Edge-TTS + gTTS fallback (20 languages)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioRecorder.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageBubble.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SearchBar.jsx
â”‚   â”‚   â”‚   â””â”€â”€ SummaryPanel.jsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ ChatPage.jsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ render.yaml
â”œâ”€â”€ vercel.json
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“ License

Built for assessment purposes. Not intended for production medical use without proper regulatory compliance.
